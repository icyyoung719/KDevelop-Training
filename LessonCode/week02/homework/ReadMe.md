总体思路：
1.分段读取文件，正好每段都可以作为一个线程
2.将每一个搜索的字符串作为每个文件段的子进程
3.每个字符串，都有一个文件，作为位置的输出，每个字符串分析完成后，可以直接输出，然后释放内存
4.每个文件段完成对所有的字符串的搜索后，可以释放相应的内存
5.对每个字符串创建一个.txt文件，用于存放出现的位置，在每个文件段进程结束后更新，写入后清空相应的vector
6.字符串有Panda等纯字符，还有<sublink linktype="nav"><anchor>这种xml元素
 

1. 文件读取与内存映射
使用内存映射文件（mmap）实现高效读取。这样可以直接将1GB的XML文件映射到内存，不用一次性加载到物理内存中，而是按需分页访问，避免高内存占用。
通过mmap函数将文件映射到内存，可以通过直接操作指针来访问文件内容。

4. 快速字符串匹配算法
Aho-Corasick算法：对于多个关键词的搜索，构建关键词的字典树（Trie），并使用Aho-Corasick算法，可以在单次扫描过程中匹配所有关键词。
Boyer-Moore算法：如果关键词较少且文件较大，可以使用Boyer-Moore算法。它的特性适合在大文本中查找单个长关键词。
使用这些高效算法加速匹配操作，并在每个线程中独立运行。

## 设计思路
- 对于xml元素，可以选择使用Aho-Corasick共同搜索
- 可以使用std::string::find进行对比分析


## 高级功能
- 存放字符串出现位置的.txt文件写入时，线程要确保按序，可以保证按序写入
- 对于有不同特征的输入字符串，根据其长度、是否为<sublink linktype="nav"><anchor>式的xml元素 等方式，选择合适的搜索方式


### BM算法测试思路
- 每次读取文件的50mb作为一块作为一个线程A，每一块再根据 字符串数目，设置相应数目的子线程B
- 每一个线程B运行后都会返回一个vector<int>，存放字符串出现的位置，他的size即为当前块中字符串出现数目
- 具有相同待匹配字符串的线程B的vector<int>最后合并到改字符串的总vector<int>中
- 每当总vector<int>有大于10 000个元素时，和最后完毕时，将其写入到相应string_out.txt中，该字符串的nums+10 000或相应的size
- 最后，在相应times.txt的写入相应字符串及其匹配成功的nums

### AC算法
- 类似BM算法
- 由于使用字符串树，因此无需创建子线程B，只需要file_size / 50mb个子线程
- 什么时候保存：？

### 其他
- 由于  <sublink linktype="nav"><anchor>_out.txt  等无法作为文件名，因此使用sanitize_filename处理文件名，替换不合格的字符

